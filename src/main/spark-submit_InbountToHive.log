spark-submit --packages com.databricks:spark-avro_2.11:4.0.0 --class com.poc.spark.InboundToHive /home/rajeshs/jars_from_intellij/new_jars/poc_hivetohbase_2.11-0.1.jar rajeshs_task_db retail_invoice_incr_avro
SPARK_MAJOR_VERSION is set to 2, using Spark2
Ivy Default Cache set to: /home/rajeshs/.ivy2/cache
The jars for the packages stored in: /home/rajeshs/.ivy2/jars
:: loading settings :: url = jar:file:/usr/hdp/2.6.5.0-292/spark2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.databricks#spark-avro_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
        confs: [default]
        found com.databricks#spark-avro_2.11;4.0.0 in central
        found org.slf4j#slf4j-api;1.7.5 in central
        found org.apache.avro#avro;1.7.6 in central
        found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
        found org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central
        found com.thoughtworks.paranamer#paranamer;2.3 in central
        found org.xerial.snappy#snappy-java;1.0.5 in central
        found org.apache.commons#commons-compress;1.4.1 in central
        found org.tukaani#xz;1.0 in central
:: resolution report :: resolve 2095ms :: artifacts dl 7ms
        :: modules in use:
        com.databricks#spark-avro_2.11;4.0.0 from central in [default]
        com.thoughtworks.paranamer#paranamer;2.3 from central in [default]
        org.apache.avro#avro;1.7.6 from central in [default]
        org.apache.commons#commons-compress;1.4.1 from central in [default]
        org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
        org.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]
        org.slf4j#slf4j-api;1.7.5 from central in [default]
        org.tukaani#xz;1.0 from central in [default]
        org.xerial.snappy#snappy-java;1.0.5 from central in [default]
        :: evicted modules:
        org.slf4j#slf4j-api;1.6.4 by [org.slf4j#slf4j-api;1.7.5] in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   10  |   1   |   1   |   1   ||   9   |   0   |
        ---------------------------------------------------------------------

:: problems summary ::
:::: ERRORS
        unknown resolver null


:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
:: retrieving :: org.apache.spark#spark-submit-parent
        confs: [default]
        0 artifacts copied, 9 already retrieved (0kB/8ms)
19/03/16 13:55:22 INFO SparkContext: Running Spark version 2.3.0.2.6.5.0-292
19/03/16 13:55:22 INFO SparkContext: Submitted application: com.poc.spark.InboundToHive
19/03/16 13:55:22 INFO SecurityManager: Changing view acls to: rajeshs
19/03/16 13:55:22 INFO SecurityManager: Changing modify acls to: rajeshs
19/03/16 13:55:22 INFO SecurityManager: Changing view acls groups to:
19/03/16 13:55:22 INFO SecurityManager: Changing modify acls groups to:
19/03/16 13:55:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rajeshs); groups with view permissions: Set(); users  with modify permissions: Set(rajeshs); groups with modify permissions: Set()
19/03/16 13:55:23 INFO Utils: Successfully started service 'sparkDriver' on port 50400.
19/03/16 13:55:23 INFO SparkEnv: Registering MapOutputTracker
19/03/16 13:55:23 INFO SparkEnv: Registering BlockManagerMaster
19/03/16 13:55:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/03/16 13:55:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/03/16 13:55:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4e197078-7f99-425c-922e-6d4258f8f17f
19/03/16 13:55:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/03/16 13:55:23 INFO SparkEnv: Registering OutputCommitCoordinator
19/03/16 13:55:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/03/16 13:55:23 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/03/16 13:55:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://gw02.itversity.com:4041
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar at spark://gw02.itversity.com:50400/jars/com.databricks_spark-avro_2.11-4.0.0.jar with timestamp 1552758924164
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar at spark://gw02.itversity.com:50400/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.apache.avro_avro-1.7.6.jar at spark://gw02.itversity.com:50400/jars/org.apache.avro_avro-1.7.6.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://gw02.itversity.com:50400/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://gw02.itversity.com:50400/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar at spark://gw02.itversity.com:50400/jars/com.thoughtworks.paranamer_paranamer-2.3.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar at spark://gw02.itversity.com:50400/jars/org.xerial.snappy_snappy-java-1.0.5.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar at spark://gw02.itversity.com:50400/jars/org.apache.commons_commons-compress-1.4.1.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.tukaani_xz-1.0.jar at spark://gw02.itversity.com:50400/jars/org.tukaani_xz-1.0.jar with timestamp 1552758924165
19/03/16 13:55:24 INFO SparkContext: Added JAR file:/home/rajeshs/jars_from_intellij/new_jars/poc_hivetohbase_2.11-0.1.jar at spark://gw02.itversity.com:50400/jars/poc_hivetohbase_2.11-0.1.jar with timestamp 1552758924166
19/03/16 13:55:24 INFO Executor: Starting executor ID driver on host localhost
19/03/16 13:55:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60785.
19/03/16 13:55:24 INFO NettyBlockTransferService: Server created on gw02.itversity.com:60785
19/03/16 13:55:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/03/16 13:55:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, gw02.itversity.com, 60785, None)
19/03/16 13:55:24 INFO BlockManagerMasterEndpoint: Registering block manager gw02.itversity.com:60785 with 366.3 MB RAM, BlockManagerId(driver, gw02.itversity.com, 60785, None)
19/03/16 13:55:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, gw02.itversity.com, 60785, None)
19/03/16 13:55:24 INFO BlockManager: external shuffle service port = 7447
19/03/16 13:55:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, gw02.itversity.com, 60785, None)
19/03/16 13:55:25 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/local-1552758924184
inside the main
inside the args.length
Below application arguments passed
database_name = rajeshs_task_db
table_name = retail_invoice_incr_avro
+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+--------+
|InvoiceNo|StockCode|Description                     |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |datestr |
+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+--------+
|581214   |23494    |VINTAGE DOILY DELUXE SEWING KIT |12      |2011-12-08 08:32:00|5.95     |14251.0   |United Kingdom|20111208|
|581214   |22969    |HOMEMADE JAM SCENTED CANDLES    |60      |2011-12-08 08:32:00|1.45     |14251.0   |United Kingdom|20111208|
+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+--------+
only showing top 2 rows

+---------------+
|   databaseName|
+---------------+
|rajeshs_task_db|
+---------------+

inside the table check
rajeshs_task_db.retail_invoice_incr_avro doesn't exists
creating table retail_invoice_incr_avro
retail_invoice_incr_avro is completed
