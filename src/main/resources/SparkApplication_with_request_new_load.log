spark-submit --packages com.databricks:spark-avro_2.11:4.0.0 --class com.poc.spark.InboundToHive /home/rajeshs/jars_from_intellij/new_jars/poc_hivetohbase_2.11-0.1.jar rajeshs_task_db retail_invoice_incr_avro request_load test


SPARK_MAJOR_VERSION is set to 2, using Spark2
Ivy Default Cache set to: /home/rajeshs/.ivy2/cache
The jars for the packages stored in: /home/rajeshs/.ivy2/jars
:: loading settings :: url = jar:file:/usr/hdp/2.6.5.0-292/spark2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.databricks#spark-avro_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
        confs: [default]
        found com.databricks#spark-avro_2.11;4.0.0 in central
        found org.slf4j#slf4j-api;1.7.5 in central
        found org.apache.avro#avro;1.7.6 in central
        found org.codehaus.jackson#jackson-core-asl;1.9.13 in central
        found org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central
        found com.thoughtworks.paranamer#paranamer;2.3 in central
        found org.xerial.snappy#snappy-java;1.0.5 in central
        found org.apache.commons#commons-compress;1.4.1 in central
        found org.tukaani#xz;1.0 in central
:: resolution report :: resolve 1799ms :: artifacts dl 6ms
        :: modules in use:
        com.databricks#spark-avro_2.11;4.0.0 from central in [default]
        com.thoughtworks.paranamer#paranamer;2.3 from central in [default]
        org.apache.avro#avro;1.7.6 from central in [default]
        org.apache.commons#commons-compress;1.4.1 from central in [default]
        org.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]
        org.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]
        org.slf4j#slf4j-api;1.7.5 from central in [default]
        org.tukaani#xz;1.0 from central in [default]
        org.xerial.snappy#snappy-java;1.0.5 from central in [default]
        :: evicted modules:
        org.slf4j#slf4j-api;1.6.4 by [org.slf4j#slf4j-api;1.7.5] in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   10  |   1   |   1   |   1   ||   9   |   0   |
        ---------------------------------------------------------------------

:: problems summary ::
:::: ERRORS
        unknown resolver null


:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
:: retrieving :: org.apache.spark#spark-submit-parent
        confs: [default]
        0 artifacts copied, 9 already retrieved (0kB/8ms)
19/03/17 06:46:41 INFO SparkContext: Running Spark version 2.3.0.2.6.5.0-292
19/03/17 06:46:41 INFO SparkContext: Submitted application: com.poc.spark.InboundToHive
19/03/17 06:46:41 INFO SecurityManager: Changing view acls to: rajeshs
19/03/17 06:46:41 INFO SecurityManager: Changing modify acls to: rajeshs
19/03/17 06:46:41 INFO SecurityManager: Changing view acls groups to:
19/03/17 06:46:41 INFO SecurityManager: Changing modify acls groups to:
19/03/17 06:46:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rajesh                         s); groups with view permissions: Set(); users  with modify permissions: Set(rajeshs); groups with modify permissions: Set()
19/03/17 06:46:41 INFO Utils: Successfully started service 'sparkDriver' on port 52550.
19/03/17 06:46:41 INFO SparkEnv: Registering MapOutputTracker
19/03/17 06:46:41 INFO SparkEnv: Registering BlockManagerMaster
19/03/17 06:46:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/03/17 06:46:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/03/17 06:46:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-52c880e4-2f9f-4354-9efb-e3d7a3ae1e87
19/03/17 06:46:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
19/03/17 06:46:41 INFO SparkEnv: Registering OutputCommitCoordinator
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.
19/03/17 06:46:42 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.
19/03/17 06:46:42 INFO Utils: Successfully started service 'SparkUI' on port 4051.
19/03/17 06:46:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://gw02.itversity.com:4051
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar at spark://gw02.itve                         rsity.com:52550/jars/com.databricks_spark-avro_2.11-4.0.0.jar with timestamp 1552819602405
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.slf4j_slf4j-api-1.7.5.jar at spark://gw02.itversity.com:5                         2550/jars/org.slf4j_slf4j-api-1.7.5.jar with timestamp 1552819602405
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.apache.avro_avro-1.7.6.jar at spark://gw02.itversity.com:                         52550/jars/org.apache.avro_avro-1.7.6.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://g                         w02.itversity.com:52550/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark:/                         /gw02.itversity.com:52550/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar at spark://gw02.                         itversity.com:52550/jars/com.thoughtworks.paranamer_paranamer-2.3.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar at spark://gw02.itver                         sity.com:52550/jars/org.xerial.snappy_snappy-java-1.0.5.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar at spark://gw02                         .itversity.com:52550/jars/org.apache.commons_commons-compress-1.4.1.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:///home/rajeshs/.ivy2/jars/org.tukaani_xz-1.0.jar at spark://gw02.itversity.com:52550/ja                         rs/org.tukaani_xz-1.0.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO SparkContext: Added JAR file:/home/rajeshs/jars_from_intellij/new_jars/poc_hivetohbase_2.11-0.1.jar at spark://gw02.i                         tversity.com:52550/jars/poc_hivetohbase_2.11-0.1.jar with timestamp 1552819602406
19/03/17 06:46:42 INFO Executor: Starting executor ID driver on host localhost
19/03/17 06:46:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55225.
19/03/17 06:46:42 INFO NettyBlockTransferService: Server created on gw02.itversity.com:55225
19/03/17 06:46:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/03/17 06:46:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, gw02.itversity.com, 55225, None)
19/03/17 06:46:42 INFO BlockManagerMasterEndpoint: Registering block manager gw02.itversity.com:55225 with 366.3 MB RAM, BlockManagerId(driv                         er, gw02.itversity.com, 55225, None)
19/03/17 06:46:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, gw02.itversity.com, 55225, None)
19/03/17 06:46:42 INFO BlockManager: external shuffle service port = 7447
19/03/17 06:46:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, gw02.itversity.com, 55225, None)
19/03/17 06:46:43 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/local-1552819602427
inside the main
database_name = rajeshs_task_db
table_name = retail_invoice_incr_avro
*****isNewLoadRequested is true****
19/03/17 06:46:44 INFO SharedState: loading hive config file: file:/etc/spark2/2.6.5.0-292/0/hive-site.xml
19/03/17 06:46:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/rajes                         hs/spark-warehouse').
19/03/17 06:46:44 INFO SharedState: Warehouse path is 'file:/home/rajeshs/spark-warehouse'.
19/03/17 06:46:44 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/03/17 06:46:44 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/03/17 06:46:45 INFO metastore: Trying to connect to metastore with URI thrift://nn01.itversity.com:9083
19/03/17 06:46:45 INFO metastore: Connected to metastore.
19/03/17 06:47:00 INFO SessionState: Created local directory: /tmp/910ed6a7-b28b-4ea4-afc0-6c8d627f15c6_resources
19/03/17 06:47:01 INFO SessionState: Created HDFS directory: /tmp/hive/rajeshs/910ed6a7-b28b-4ea4-afc0-6c8d627f15c6
19/03/17 06:47:01 INFO SessionState: Created local directory: /tmp/rajeshs/910ed6a7-b28b-4ea4-afc0-6c8d627f15c6
19/03/17 06:47:01 INFO SessionState: Created HDFS directory: /tmp/hive/rajeshs/910ed6a7-b28b-4ea4-afc0-6c8d627f15c6/_tmp_space.db
19/03/17 06:47:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/rajeshs/spark-warehouse
 The available files at inbound location are
2010-12-01.csv
2010-12-02.csv
picking latest file from inbound
latest file name : 2010-12-02.csv
filname for reading dataframe2010-12-02.csv
+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+--------+
|InvoiceNo|StockCode|Description          |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |datestr |
+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+--------+
|536598   |21421    |PORCELAIN ROSE LARGE |12      |2010-12-02 07:48:00|1.25     |13090.0   |United Kingdom|20101202|
|536598   |21422    |PORCELAIN ROSE SMALL |16      |2010-12-02 07:48:00|0.85     |13090.0   |United Kingdom|20101202|
+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+--------+
only showing top 2 rows

current_partition 20101202 and fileValue 20101202
file was already processed
file is already processed...
 load requested with new file from local to inbound
latest local filename : 2010-12-03.csv
file copied to inbound location
file backup is successful
reloading inbound with new data
 The available files at inbound location are
2010-12-01.csv
2010-12-02.csv
2010-12-03.csv
picking latest file from inbound
latest file name : 2010-12-03.csv
filname for reading dataframe2010-12-03.csv
isReloaded = true
+---------+---------+----------------------+--------+-------------------+---------+----------+--------------+--------+
|InvoiceNo|StockCode|Description           |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |datestr |
+---------+---------+----------------------+--------+-------------------+---------+----------+--------------+--------+
|536847   |22155    |STAR DECORATION RUSTIC|48      |2010-12-03 09:31:00|0.42     |17135.0   |United Kingdom|20101203|
+---------+---------+----------------------+--------+-------------------+---------+----------+--------------+--------+
only showing top 1 row

Inserting new data to table
rajeshs_task_db.retail_invoice_incr_avro is exists
+--------+-----+
| datestr|count|
+--------+-----+
|20101202| 8436|
|20101201| 3108|
+--------+-----+

inserting into retail_invoice_incr_avro
records to be added to existing table is 2202
insertion is completed
new data insertion is completed
+--------+-----+
| datestr|count|
+--------+-----+
|20101202| 8436|
|20101203| 2202|
|20101201| 3108|
+--------+-----+

total number of records :13746
total number of unique records :7317
******job is completed******
